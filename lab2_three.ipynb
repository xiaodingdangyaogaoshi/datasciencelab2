{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "DATA_PATH = \"./data\"\n",
    "\n",
    "# 读入数据阶段\n",
    "with open(DATA_PATH+\"/stopwords.txt\", 'r') as file:\n",
    "    stopwords = file.read()\n",
    "stopwords = stopwords.split('\\n')\n",
    "\n",
    "amazon_df = pd.read_csv(DATA_PATH+\"/Amazon.csv\")\n",
    "google_df = pd.read_csv(DATA_PATH+\"/Google.csv\")\n",
    "perfectMap_df = pd.read_csv(DATA_PATH+\"/Amazon_Google_perfectMapping.csv\")\n",
    "perfectMap = []\n",
    "\n",
    "def buildPerfectMap(x):\n",
    "    perfectMap.append((x['idAmazon'], x['idGoogleBase']))\n",
    "perfectMap_df.apply(buildPerfectMap, axis=1)\n",
    "pass\n",
    "\n",
    "def tokenize(string):\n",
    "    if not type(string) is str:\n",
    "        return []\n",
    "    split_regex = '\\w+'\n",
    "    string = string.lower()\n",
    "    tokens = re.findall(split_regex, string)\n",
    "    for word in stopwords:  # 读取所有停用词，并在 list 中删除\n",
    "        while word in tokens:\n",
    "            tokens.remove(word)\n",
    "    return tokens\n",
    "def rec2tok(x, dic):\n",
    "    # x:a record from on DataFrame\n",
    "    # dic:dictionary that build mappings from record id to tokens\n",
    "    if not type(x['description']) is str:\n",
    "        x['description'] = ''\n",
    "    if not type(x['manufacturer']) is str:\n",
    "        x['manufacturer'] = ''\n",
    "    dic[x['id']] = tokenize(x['title'] + ' ' + x['description'] + ' ' + x['manufacturer'])\n",
    "def inc(i, dic):\n",
    "    # i:a key in dic\n",
    "    # dic:dic[i]++\n",
    "    if i in dic: \n",
    "        dic[i] += 1\n",
    "    else: \n",
    "        dic[i] = 1\n",
    "    \n",
    "def tf(tokens):# 计算 tokens 中所有 token 的 tf 值\n",
    "    tfs = {}\n",
    "    for token in tokens: \n",
    "        inc(token, tfs)\n",
    "    n = float(len(tokens))\n",
    "    for token in tfs:\n",
    "        tfs[token] /= n\n",
    "    return tfs\n",
    "\n",
    "def idf(tokens_dict):\n",
    "    idfs = {}\n",
    "    N = float(len(amazon_df)+len(google_df)) # tokens 列表的个数，即 Amazon.csv, Google.csv 中每一行对应一个 tokens\n",
    "    for tid in tokens_dict:                  # 取出 tokens 列表的的每一个 tokens，计算 tokens 内包含的 所有token，在所有tokens中出现了几次\n",
    "        tokens_set = set(tokens_dict[tid])\n",
    "        for token in tokens_set:\n",
    "            inc(token, idfs)\n",
    "    for token in idfs:\n",
    "        idfs[token] = N / idfs[token]\n",
    "    return idfs\n",
    "\n",
    "\n",
    "def tfidf(tokens, idfs):\n",
    "    ans = tf(tokens)\n",
    "    for i in ans:\n",
    "        ans[i] *= idfs[i]\n",
    "    return ans \n",
    "\n",
    "\n",
    "def invertIndex(forward_index):\n",
    "    # 返回一个 {'token': []} 的字典，即每个token在那些id中出现过\n",
    "    # 即 反向索引\n",
    "    ans = {}\n",
    "    for i in forward_index:\n",
    "        for j in forward_index[i]:\n",
    "            if j in ans:\n",
    "                ans[j].append(i)\n",
    "            else:\n",
    "                ans[j] = [i]\n",
    "    return ans\n",
    "def dotprod(a, b): # 计算余弦相似度的分子， a*b 的和，点积\n",
    "    ans=0\n",
    "    for i in a:\n",
    "        if i in b: \n",
    "            ans += a[i]*b[i]\n",
    "    return ans\n",
    "\n",
    "def norm(a): # 计算余弦相似度的分母， a^2 的和，范数\n",
    "    ans = 0\n",
    "    for i in a:\n",
    "        ans += a[i]**2\n",
    "    return math.sqrt(ans)\n",
    "amazon_tokens_dict = {} \n",
    "google_tokens_dict = {}\n",
    "\n",
    "amazon_df.apply(lambda x:rec2tok(x, amazon_tokens_dict), axis=1)\n",
    "google_df.apply(lambda x:rec2tok(x, google_tokens_dict), axis=1)\n",
    "\n",
    "amazon_inv = invertIndex(amazon_tokens_dict)\n",
    "\n",
    "idfs_full = dict(Counter(idf(amazon_tokens_dict))+Counter(idf(google_tokens_dict)))\n",
    "\n",
    "amazon_weights = { i:tfidf(amazon_tokens_dict[i], idfs_full) for i in amazon_tokens_dict }\n",
    "google_weights = { i:tfidf(google_tokens_dict[i], idfs_full) for i in google_tokens_dict }\n",
    "\n",
    "amazon_norm = { i:norm(amazon_weights[i]) for i in amazon_weights }\n",
    "google_norm = { i:norm(google_weights[i]) for i in google_weights }\n",
    "def buildSim(Id, weight, norm, weights, norms, inv, sims):\n",
    "    #weights : Id->token->weight\n",
    "    #norms : Id->norm\n",
    "    for token in weight: # 循环每一个 token\n",
    "        if token in inv: # 如果该 token 在 Amazon 的数据中出现过\n",
    "            for ama_tid in inv[token]: # 在哪一个 Amazon 的数据中出现过\n",
    "                if not (ama_tid, Id) in sims: \n",
    "                    sims[(ama_tid, Id)] = dotprod(weight, weights[ama_tid]) / (norm*norms[ama_tid])  \n",
    "                    # 计算一条 Amazon 数据与一条 Google 数据的相似度\n",
    "sims={}\n",
    "for i in google_weights: # 对每一行 google 的数据\n",
    "    buildSim(i, google_weights[i], google_norm[i], amazon_weights, amazon_norm, amazon_inv, sims)\n",
    "print(len(sims))\n",
    "\n",
    "true_dup_sims = []\n",
    "\n",
    "\n",
    "# 将准确度大于阈值的实体融合条目，加入到正确 list 中\n",
    "def truepos(threshold):\n",
    "    global true_dup_sims\n",
    "    true_dup_sims = []\n",
    "    for i in sims:\n",
    "        if sims[i] > threshold: \n",
    "            true_dup_sims.append(i)\n",
    "\n",
    "\n",
    "# 大于阈值的个数 - 正确识别个数(与给定perfect一致)\n",
    "def falsepos(threshold):\n",
    "    ans=0\n",
    "    for i in true_dup_sims:\n",
    "        if not i in perfectMap: \n",
    "            ans += 1\n",
    "    return ans\n",
    "\n",
    "\n",
    "# 融合准确率 -> 正确识别个数 / 大于阈值的个数\n",
    "def precision(threshold):\n",
    "    truepos(threshold)\n",
    "    a = len(true_dup_sims) - falsepos(threshold)\n",
    "    b = len(true_dup_sims)\n",
    "    return a/b\n",
    "nthresholds = 100\n",
    "thresholds = [float(n) / nthresholds for n in range(2, nthresholds)]\n",
    "p = [precision(n) for n in thresholds]\n",
    "%pylab inline\n",
    "plt.plot(thresholds, p)\n",
    "for i in range(0, 98):\n",
    "    if p[i] == max(p): \n",
    "        print(\"最大准确率阈值: {}\".format(thresholds[i]))\n",
    "    \n",
    "print(\"最大准确率: {}\".format(max(p)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
